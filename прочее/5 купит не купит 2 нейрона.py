import numpy as np 

def relu(z):
    # находит максимальное среди всего массива или вектора как тебе удобно
    return np.maximum(0, z)

# часы, деньги, купит (1 — да, 0 — нет)
Data = np.array([
    [1, 200, 0],
    [3, 400, 0],
    [5, 600, 1],
    [7, 800, 1],
    [9, 1000, 1],
    [2, 100, 0],
])
# разсиьсковываем данные
Buy = np.array(Data[0:, 2:3])
Data = Data[0:, 0:2]
# задаём рандомные значения для цены за воздух и висов для обоих нейронов из 2 если что
bias = np.array([0.2, 0.8])
w = np.array([
    [0.5, 0.27],
    [0.98, 0.34]
])

# 1 нейрон мы просчитываем данные вот получается z1 это твоё значение
z1 = Data @ w + bias
print(relu(z1))
# ты там проверяешь что ну оно находится в пределах разумного
retur = relu(z1)


print(w[1])
# 2 нейрон тут да он уже 2
z2 = Data @ w[1] + bias[1]
print(relu(z2))
print(z2)
print(np.exp(-z2))
print(np.exp(z2))
# эта штука это выходное значение я честно пока ни ни но в общих красках
# exp делает так что бы если число большое то он делает так что бы оно стремилось к 0, а большое маленькое а потом 
# минус, и прибавляем 1 что бы ну совсем не была жопа, а потом делим что бы получить значение 1 или 0
# ну как обычно понимаешь джоске сначала длинная, а потом коротакая
print(1 / (1 + np.exp(-z2)))